{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\naura\\\\Desktop\\\\end-to-end-ML\\\\computer-vision\\\\Bone-fracture-xray-classification\\\\notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from pathlib import Path\n",
    "\n",
    "class BaseModelConfig(BaseModel):\n",
    "    root_dir: Path\n",
    "    base_model_path: Path\n",
    "    custom_trained_model_path: Path\n",
    "    params_image_size: list\n",
    "    params_learning_rate: float\n",
    "    params_include_top: bool\n",
    "    params_weights: str\n",
    "    params_classes: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from boneFractureClassification.constants import CONFIG_FILE_PATH, PARAMS_FILE_PATH\n",
    "from boneFractureClassification.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath=CONFIG_FILE_PATH,\n",
    "        params_filepath=PARAMS_FILE_PATH,):\n",
    "        \n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        \n",
    "        create_directories([self.config.artifacts_root])\n",
    "        \n",
    "    def get_base_model_config(self) -> BaseModelConfig:\n",
    "        \n",
    "        config = self.config.base_model\n",
    "        \n",
    "        create_directories([config.root_dir])\n",
    "        create_directories([config.custom_train_model_dir])\n",
    "        \n",
    "        base_model_config = BaseModelConfig(\n",
    "            root_dir = Path(config.root_dir),\n",
    "            custom_train_model_dir = Path(config.custom_train_model_dir),\n",
    "            base_model_path = Path(config.base_model_path),\n",
    "            custom_trained_model_path = Path(config.custom_trained_model_path),\n",
    "            params_image_size = self.params.IMAGE_SIZE,\n",
    "            params_learning_rate = self.params.LEARNING_RATE,\n",
    "            params_include_top = self.params.INCLUDE_TOP,\n",
    "            params_weights = self.params.WEIGHTS,\n",
    "            params_classes = self.params.CLASSES\n",
    "        )\n",
    "        \n",
    "        return base_model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request as request\n",
    "from zipfile import ZipFile\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from pathlib import Path\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel:\n",
    "    def __init__(self, config: BaseModelConfig):\n",
    "        self.config = config\n",
    "        \n",
    "    def get_base_model(self):\n",
    "        self.model = tf.keras.applications.vgg16.VGG16(\n",
    "            input_shape = self.config.params_image_size,\n",
    "            weights = self.config.params_weights,\n",
    "            include_top = self.config.params_include_top\n",
    "        )\n",
    "        \n",
    "        self.save_model(path=self.config.base_model_path, model=self.model)\n",
    "        \n",
    "    @staticmethod\n",
    "    def _prepare_full_model(model, classes, freeze_all, freeze_till, learning_rate):\n",
    "        if freeze_all:\n",
    "            for layer in model.layers:\n",
    "                model.trainable = False\n",
    "        elif (freeze_till is not None) and (freeze_till > 0):\n",
    "            for layer in model.layers[:-freeze_till]:\n",
    "                model.trainable = False\n",
    "               \n",
    "        flatten_in = Flatten()(model.output)\n",
    "        \n",
    "        prediction = Dense(\n",
    "            units = classes,\n",
    "            activation = \"softmax\"\n",
    "        )(flatten_in)\n",
    "        \n",
    "        full_model = Model(\n",
    "            inputs = model.input,\n",
    "            outputs = prediction\n",
    "        )\n",
    "        \n",
    "        optimizer = SGD(learning_rate=learning_rate)\n",
    "        loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "        full_model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=loss_fn,\n",
    "            metrics=[\"accuracy\"]\n",
    "        )\n",
    "        \n",
    "        full_model.summary()\n",
    "        return full_model\n",
    "        \n",
    "    \n",
    "    def custom_train_model(self):\n",
    "        if not hasattr(self, 'model'):\n",
    "            self.get_base_model()\n",
    "        \n",
    "        self.full_model = self._prepare_full_model(\n",
    "            model = self.model,\n",
    "            classes = self.config.params_classes,\n",
    "            freeze_all = True,\n",
    "            freeze_till = None,\n",
    "            learning_rate = self.config.params_learning_rate\n",
    "        )\n",
    "        \n",
    "        self.save_model(path=self.config.custom_trained_model_path, model=self.full_model)\n",
    "        \n",
    "    @staticmethod\n",
    "    def save_model(path: Path, model: tf.keras.Model):\n",
    "        model.save(path)\n",
    "        \n",
    "        \n",
    "    \"\"\"def load_and_compile_model(self, path: Path):\n",
    "        loaded_model = tf.keras.models.load_model(path)\n",
    "        \n",
    "        # Recreate the optimizer and compile the model\n",
    "        optimizer = SGD(learning_rate=self.config.params_learning_rate)\n",
    "        loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "        loaded_model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=loss_fn,\n",
    "            metrics=[\"accuracy\"]\n",
    "        )\n",
    "        \n",
    "        return loaded_model\"\"\"\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-02 00:59:21,818: INFO: common: yaml file: config\\config.yaml loaded successfully!]\n",
      "[2024-06-02 00:59:21,822: INFO: common: yaml file: params.yaml loaded successfully!]\n",
      "[2024-06-02 00:59:21,824: INFO: common: created directory at: artifacts]\n",
      "[2024-06-02 00:59:21,826: INFO: common: created directory at: artifacts/base_model]\n",
      "[2024-06-02 00:59:21,828: INFO: common: created directory at: artifacts/custom_train_model]\n",
      "[2024-06-02 00:59:23,997: WARNING: saving_utils: Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.]\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 528, 528, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 528, 528, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 528, 528, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 264, 264, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 264, 264, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 264, 264, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 132, 132, 128)     0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 132, 132, 256)     295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 132, 132, 256)     590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 132, 132, 256)     590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 66, 66, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 66, 66, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 66, 66, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 66, 66, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 33, 33, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 33, 33, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 33, 33, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 33, 33, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 16, 16, 512)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 131072)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 262146    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,976,834\n",
      "Trainable params: 262,146\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ModelConfigurationManager()\n",
    "    base_model_config = config.get_base_model_config()\n",
    "    base_model = BaseModel(config=base_model_config)\n",
    "    base_model.get_base_model()\n",
    "    base_model.custom_train_model()\n",
    "    #base_model.load_and_compile_model(path=\"artifacts/custom_train_model/custom_trained_base_model.h5\")\n",
    "    #base_model.custom_train_model()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bone-fracture-classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
